{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hostname = 'localhost'\n",
    "username = ''\n",
    "password = ''\n",
    "database = 'belle2'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/a1singh/anaconda3/envs/keras/bin/python\n",
      "3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \n",
      "[GCC 7.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x7fad080ee550>\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "conn = pymysql.connect(host=hostname, user=username, passwd=password, db=database)\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query       = 'SELECT * FROM Jobs WHERE Status = \\'Failed\\' '\n",
    "failedJobs    = pd.read_sql_query(query,con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofjobids = failedJobs['JobID'].tolist()\n",
    "listofjobids = list(set(listofjobids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query       = 'SELECT * FROM HeartBeatLoggingInfo WHERE JobID IN (' + ','.join((str(x) for x in listofjobids)) + ')'\n",
    "dataHBLI_failed    = pd.read_sql_query(query,con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listofjobids = list(set(failedJobs['JobID'].tolist()) - set (dataHBLI_failed.JobID.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query       = 'SELECT * FROM Jobs WHERE Status = \\'Done\\''\n",
    "successJobs    = pd.read_sql_query(query,con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "successJobs_picked = successJobs.sample(847267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofjobids = successJobs['JobID'].tolist()\n",
    "listofjobids = list(set(listofjobids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query   = 'SELECT * FROM HeartBeatLoggingInfo WHERE JobID IN (' + ','.join((str(x) for x in listofjobids)) + ')'\n",
    "dataHBLI_success = pd.read_sql_query(query,con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x7f61439b9c88>\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from IPython.display import display, HTML\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^####################################\n",
    "####################################^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^####################################\n",
    "####################################^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^####################################\n",
    "####################################^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^####################################\n",
    "####################################^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pieces = (failedJobs, successJobs_picked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allJobs = pd.concat(pieces, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pieces = (dataHBLI_failed, dataHBLI_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allHBLI = pd.concat(pieces, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allHBLI.Value = pd.to_numeric(allHBLI['Value'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allHBLI.HeartBeatTime = pd.to_datetime(allHBLI['HeartBeatTime'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allHBLI_wide=allHBLI.pivot_table(index=['JobID','HeartBeatTime'], columns='Name', values='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the last few rows\n",
    "allHBLI_wide = allHBLI_wide.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "allHBLI_wide[['AvailableDiskSpace', 'CPUConsumed', 'LoadAverage', \n",
    "             'MemoryUsed', 'RSS','Vsize', 'WallClockTime']] = scaler.fit_transform(allHBLI_wide[['AvailableDiskSpace', \n",
    "                                                                        'CPUConsumed', 'LoadAverage', 'MemoryUsed', \n",
    "                                                                        'RSS','Vsize', 'WallClockTime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allHBLI_wide = allHBLI_wide.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataJobs = allJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofcolumns = dataJobs.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removelist = ['JobID','JobName','SubmissionTime', 'RescheduleTime', 'LastUpdateTime', \n",
    "              'StartExecTime', 'HeartBeatTime', 'EndExecTime']\n",
    "\n",
    "for r in removelist:\n",
    "    listofcolumns.remove(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = {}\n",
    "\n",
    "for c in listofcolumns:\n",
    "    #print(c)\n",
    "    ll = len(dataJobs[c].unique().tolist())\n",
    "    \n",
    "    if ll > 0:\n",
    "        #print('************ found > limit *')\n",
    "        cc[c]=ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dataJobs['MinorStatus']\n",
    "del dataJobs['ApplicationStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in sorted(cc, key=cc.get, reverse=False):\n",
    "    if cc[w] == 1:\n",
    "        del dataJobs[w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dataJobs['JobName'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataJobs['start_submit'] = (dataJobs['StartExecTime']-dataJobs['SubmissionTime']) / np.timedelta64(1, 'm')\n",
    "dataJobs['hbeat_start']  = (dataJobs['HeartBeatTime']-dataJobs['StartExecTime']) / np.timedelta64(1, 'm')\n",
    "\n",
    "for x in ['SubmissionTime','RescheduleTime','LastUpdateTime','StartExecTime','HeartBeatTime','EndExecTime']:\n",
    "    del dataJobs[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dataJobs['AccountedFlag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj_encoded = pd.get_dummies(dataJobs, columns=['JobType','JobGroup','Site','Status','UserPriority'],\n",
    "                           drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allJobs_encoded = dj_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesscols = allJobs_encoded.columns.tolist()\n",
    "\n",
    "### Extra removal after noticing high accuracy\n",
    "lesscols.remove('hbeat_start')\n",
    "lesscols.remove('start_submit')\n",
    "\n",
    "lesscols = [x for x in lesscols if x.find('Owner')==-1]\n",
    "\n",
    "##############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allJobs_encodedsmall = allJobs_encoded[lesscols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allJobs_encoded = allJobs_encodedsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_samples = pd.merge(allHBLI_wide, allJobs_encoded, on =['JobID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sample_counts = pd.value_counts(raw_samples['JobID'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac7dfa41d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sample_counts.values, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholdd = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned = raw_samples[~raw_samples['JobID'].isin(remove_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalleftjobslist = cleaned.JobID.unique().tolist()\n",
    "totalleftjobs = len(cleaned.JobID.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "indices = random.sample(range(len(totalleftjobslist)), int(totalleftjobs * .50))\n",
    "takeoutlist = [totalleftjobslist[i] for i in sorted(indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "801845\n"
     ]
    }
   ],
   "source": [
    "remove_list = remove_list + takeoutlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = raw_samples[~raw_samples['JobID'].isin(remove_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeoutdf = raw_samples[raw_samples['JobID'].isin(takeoutlist)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_counts = pd.value_counts(cleaned['JobID'].values, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samples_features(df_input):\n",
    "    \n",
    "    k = thresholdd\n",
    "    input_cols = train_feat\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['single_input_vector'] = df_input[input_cols].apply(tuple, axis=1).apply(list)\n",
    "    \n",
    "    df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])\n",
    "        \n",
    "    df['cumulative_input_vectors'] = df['single_input_vector'].shift(0)\n",
    "    \n",
    "    for i in range(1,k):\n",
    "        df['cumulative_input_vectors'] += df['single_input_vector'].shift(i)\n",
    "          \n",
    "    df.dropna(inplace=True)     # does operation in place & returns None\n",
    "\n",
    "    X_ = np.asarray(df.cumulative_input_vectors)\n",
    "    \n",
    "    X = np.vstack(X_).reshape(len(df), k, len(input_cols))\n",
    "    \n",
    "    # Clean up\n",
    "    del df\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_col = ['Status_Failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned = cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = cleaned.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = cleaned.columns.tolist()\n",
    "\n",
    "train_feat.remove('HeartBeatTime')\n",
    "train_feat.remove('WallClockTime')\n",
    "train_feat.remove('JobID')\n",
    "train_feat.remove('Status_Failed')\n",
    "\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedgrouped = cleaned.groupby('JobID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return retLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collecttrain = applyParallel(cleanedgrouped, samples_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in collecttrain:\n",
    "    #len(x)\n",
    "    for i in x:\n",
    "        X.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_col = ['Status_Failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samples_label(df_input):\n",
    "    \n",
    "    k = thresholdd\n",
    "    input_cols = label_col\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['single_input_vector'] = df_input[input_cols].apply(tuple, axis=1).apply(list)\n",
    "    \n",
    "    df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])\n",
    "        \n",
    "    df['cumulative_input_vectors'] = df['single_input_vector'].shift(0)\n",
    "    \n",
    "    for i in range(1,k):\n",
    "        df['cumulative_input_vectors'] += df['single_input_vector'].shift(i)\n",
    "          \n",
    "    df.dropna(inplace=True)     # does operation in place & returns None\n",
    "\n",
    "    X_ = np.asarray(df.cumulative_input_vectors)\n",
    "    \n",
    "    X = np.vstack(X_).reshape(len(df), k, len(input_cols))\n",
    "    \n",
    "    # Clean up\n",
    "    del df\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Y (each job separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanedgrouped = cleaned.groupby('JobID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectlabel = applyParallel(cleanedgrouped, samples_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in collectlabel:\n",
    "    #len(x)\n",
    "    for i in x:\n",
    "        Y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = np.array([x[0][0] for x in Y]).reshape(len(Y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    import numpy as np\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_final, Y_final = unison_shuffled_copies(X,YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "takeoutdf = takeoutdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "takeoutdfgrouped = takeoutdf.groupby('JobID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collectXtest = applyParallel(takeoutdfgrouped, samples_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42849294 Lengths match\n",
      "37304595 Lengths match\n",
      "41515302 Lengths match\n",
      "33169777 Lengths match\n",
      "43003503 Lengths match\n",
      "44079441 Lengths match\n",
      "47573569 Lengths match\n",
      "43613146 Lengths match\n",
      "45807203 Lengths match\n",
      "37688976 Lengths match\n",
      "41594301 Lengths match\n",
      "37604903 Lengths match\n",
      "46637189 Lengths match\n",
      "46247603 Lengths match\n",
      "45762130 Lengths match\n",
      "42818419 Lengths match\n",
      "45457464 Lengths match\n",
      "39959275 Lengths match\n",
      "43042653 Lengths match\n",
      "45132138 Lengths match\n"
     ]
    }
   ],
   "source": [
    "# Testcase 1 of function sample_features:\n",
    "\n",
    "check = 0\n",
    "j_checks = takeoutdf.JobID.sample(20)\n",
    "\n",
    "for k in j_checks:\n",
    "    \n",
    "    v = takeoutdfgrouped.get_group(k)\n",
    "    \n",
    "    if(True):\n",
    "        #print(v.columns.tolist())\n",
    "        A = np.array(v)\n",
    "        #print(train_feat)\n",
    "        B = samples_features(v)\n",
    "        check += 1\n",
    "        \n",
    "        if(len(A) == len(B)):\n",
    "            print(k, 'Lengths match')\n",
    "        else:\n",
    "            print(k, 'Lengths NOT match')\n",
    "        \n",
    "        # Tests\n",
    "        for x,y in zip(A,B):\n",
    "            #print(x)\n",
    "            #print(y)\n",
    "            \n",
    "            if not (np.all([ m==n for (m,n) in zip(x[2:8] , y[0][0:6]) ])):\n",
    "                print(k, 'NOK')\n",
    "                \n",
    "    if(check == len(j_checks)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in collectXtest:\n",
    "    #len(x)\n",
    "    for i in x:\n",
    "        X_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## X_test is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collecttestlabel = applyParallel(takeoutdfgrouped, samples_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_t=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in collecttestlabel:\n",
    "    #len(x)\n",
    "    for i in x:\n",
    "        Y_t.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_t = np.array(Y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array([x[0][0] for x in Y_t]).reshape(len(Y_t),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "import pickle \n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "input_length    = X_final.shape[1]\n",
    "input_dim       = X_final.shape[2]\n",
    "output_dim      = len(Y_final[0])\n",
    "\n",
    "def create_model1(input_dim = input_dim, input_length = input_length, output_dim=output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(20))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model       = create_model1()\n",
    "history     = model.fit(X_final,Y_final,batch_size=250, epochs=100, validation_split = 0.10, verbose = 1)\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "y_pred      = model.predict(X_test)\n",
    "y_true      = pd.Series([x[0] for x in Y_test])\n",
    "y_predicted = pd.Series([ np.rint(j[0]) for j in y_pred])\n",
    "\n",
    "precision, recall, fscore, support = score(y_true, y_predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model2(input_dim = input_dim, input_length = input_length, output_dim=output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(50, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(50, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model       = create_model2()\n",
    "history     = model.fit(X_final,Y_final,batch_size=250, epochs=100, validation_split = 0.10, verbose = 1)\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "y_pred      = model.predict(X_test)\n",
    "y_true      = pd.Series([x[0] for x in Y_test])\n",
    "y_predicted = pd.Series([ np.rint(j[0]) for j in y_pred])\n",
    "\n",
    "precision, recall, fscore, support = score(y_true, y_predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
