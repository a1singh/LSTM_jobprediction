{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/a1singh/anaconda3/envs/keras/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model 1...\n",
      "Compiling...\n",
      "Train on 12651032 samples, validate on 1405671 samples\n",
      "Epoch 1/100\n",
      "12651032/12651032 [==============================] - 344s 27us/step - loss: 0.4957 - binary_accuracy: 0.7587 - val_loss: 0.4809 - val_binary_accuracy: 0.7689\n",
      "Epoch 2/100\n",
      "12651032/12651032 [==============================] - 368s 29us/step - loss: 0.4768 - binary_accuracy: 0.7715 - val_loss: 0.4730 - val_binary_accuracy: 0.7737\n",
      "Epoch 3/100\n",
      "12651032/12651032 [==============================] - 363s 29us/step - loss: 0.4690 - binary_accuracy: 0.7758 - val_loss: 0.4646 - val_binary_accuracy: 0.7784\n",
      "Epoch 4/100\n",
      "12651032/12651032 [==============================] - 366s 29us/step - loss: 0.4621 - binary_accuracy: 0.7793 - val_loss: 0.4593 - val_binary_accuracy: 0.7795\n",
      "Epoch 5/100\n",
      "12651032/12651032 [==============================] - 369s 29us/step - loss: 0.4568 - binary_accuracy: 0.7817 - val_loss: 0.4543 - val_binary_accuracy: 0.7830\n",
      "Epoch 6/100\n",
      "12651032/12651032 [==============================] - 373s 29us/step - loss: 0.4525 - binary_accuracy: 0.7841 - val_loss: 0.4506 - val_binary_accuracy: 0.7853\n",
      "Epoch 7/100\n",
      "12651032/12651032 [==============================] - 375s 30us/step - loss: 0.4488 - binary_accuracy: 0.7864 - val_loss: 0.4467 - val_binary_accuracy: 0.7876\n",
      "Epoch 8/100\n",
      "12651032/12651032 [==============================] - 367s 29us/step - loss: 0.4454 - binary_accuracy: 0.7883 - val_loss: 0.4461 - val_binary_accuracy: 0.7879\n",
      "Epoch 9/100\n",
      "12651032/12651032 [==============================] - 350s 28us/step - loss: 0.4424 - binary_accuracy: 0.7899 - val_loss: 0.4405 - val_binary_accuracy: 0.7910\n",
      "Epoch 10/100\n",
      "12651032/12651032 [==============================] - 357s 28us/step - loss: 0.4402 - binary_accuracy: 0.7910 - val_loss: 0.4392 - val_binary_accuracy: 0.7917\n",
      "Epoch 11/100\n",
      "12651032/12651032 [==============================] - 362s 29us/step - loss: 0.4384 - binary_accuracy: 0.7919 - val_loss: 0.4379 - val_binary_accuracy: 0.7923\n",
      "Epoch 12/100\n",
      "12651032/12651032 [==============================] - 374s 30us/step - loss: 0.4369 - binary_accuracy: 0.7927 - val_loss: 0.4378 - val_binary_accuracy: 0.7926\n",
      "Epoch 13/100\n",
      "12651032/12651032 [==============================] - 372s 29us/step - loss: 0.4357 - binary_accuracy: 0.7934 - val_loss: 0.4348 - val_binary_accuracy: 0.7940\n",
      "Epoch 14/100\n",
      "12651032/12651032 [==============================] - 354s 28us/step - loss: 0.4347 - binary_accuracy: 0.7941 - val_loss: 0.4362 - val_binary_accuracy: 0.7939\n",
      "Epoch 15/100\n",
      "12651032/12651032 [==============================] - 374s 30us/step - loss: 0.4337 - binary_accuracy: 0.7947 - val_loss: 0.4335 - val_binary_accuracy: 0.7951\n",
      "Epoch 16/100\n",
      "12651032/12651032 [==============================] - 349s 28us/step - loss: 0.4328 - binary_accuracy: 0.7952 - val_loss: 0.4316 - val_binary_accuracy: 0.7961\n",
      "Epoch 17/100\n",
      "12651032/12651032 [==============================] - 366s 29us/step - loss: 0.4320 - binary_accuracy: 0.7958 - val_loss: 0.4321 - val_binary_accuracy: 0.7958\n",
      "Epoch 18/100\n",
      "12651032/12651032 [==============================] - 347s 27us/step - loss: 0.4312 - binary_accuracy: 0.7964 - val_loss: 0.4326 - val_binary_accuracy: 0.7952\n",
      "Epoch 19/100\n",
      "12651032/12651032 [==============================] - 354s 28us/step - loss: 0.4304 - binary_accuracy: 0.7969 - val_loss: 0.4299 - val_binary_accuracy: 0.7976\n",
      "Epoch 20/100\n",
      "12651032/12651032 [==============================] - 374s 30us/step - loss: 0.4296 - binary_accuracy: 0.7974 - val_loss: 0.4306 - val_binary_accuracy: 0.7976\n",
      "Epoch 21/100\n",
      "12651032/12651032 [==============================] - 362s 29us/step - loss: 0.4289 - binary_accuracy: 0.7979 - val_loss: 0.4287 - val_binary_accuracy: 0.7984\n",
      "Epoch 22/100\n",
      "12651032/12651032 [==============================] - 369s 29us/step - loss: 0.4282 - binary_accuracy: 0.7984 - val_loss: 0.4279 - val_binary_accuracy: 0.7996\n",
      "Epoch 23/100\n",
      "12651032/12651032 [==============================] - 349s 28us/step - loss: 0.4276 - binary_accuracy: 0.7987 - val_loss: 0.4294 - val_binary_accuracy: 0.7988\n",
      "Epoch 24/100\n",
      "12651032/12651032 [==============================] - 362s 29us/step - loss: 0.4269 - binary_accuracy: 0.7992 - val_loss: 0.4277 - val_binary_accuracy: 0.7980\n",
      "Epoch 25/100\n",
      "12651032/12651032 [==============================] - 365s 29us/step - loss: 0.4264 - binary_accuracy: 0.7996 - val_loss: 0.4262 - val_binary_accuracy: 0.7993\n",
      "Epoch 26/100\n",
      "12651032/12651032 [==============================] - 335s 26us/step - loss: 0.4258 - binary_accuracy: 0.7998 - val_loss: 0.4280 - val_binary_accuracy: 0.7997\n",
      "Epoch 27/100\n",
      "12651032/12651032 [==============================] - 359s 28us/step - loss: 0.4254 - binary_accuracy: 0.8000 - val_loss: 0.4263 - val_binary_accuracy: 0.7984\n",
      "Epoch 28/100\n",
      "12651032/12651032 [==============================] - 331s 26us/step - loss: 0.4250 - binary_accuracy: 0.8003 - val_loss: 0.4273 - val_binary_accuracy: 0.7977\n",
      "Epoch 29/100\n",
      "12651032/12651032 [==============================] - 338s 27us/step - loss: 0.4246 - binary_accuracy: 0.8005 - val_loss: 0.4254 - val_binary_accuracy: 0.7997\n",
      "Epoch 30/100\n",
      "12651032/12651032 [==============================] - 309s 24us/step - loss: 0.4242 - binary_accuracy: 0.8007 - val_loss: 0.4232 - val_binary_accuracy: 0.8013\n",
      "Epoch 31/100\n",
      "12651032/12651032 [==============================] - 328s 26us/step - loss: 0.4240 - binary_accuracy: 0.8009 - val_loss: 0.4236 - val_binary_accuracy: 0.8016\n",
      "Epoch 32/100\n",
      "12651032/12651032 [==============================] - 312s 25us/step - loss: 0.4236 - binary_accuracy: 0.8011 - val_loss: 0.4238 - val_binary_accuracy: 0.8008\n",
      "Epoch 33/100\n",
      "12651032/12651032 [==============================] - 331s 26us/step - loss: 0.4234 - binary_accuracy: 0.8012 - val_loss: 0.4233 - val_binary_accuracy: 0.8018\n",
      "Epoch 34/100\n",
      "12651032/12651032 [==============================] - 317s 25us/step - loss: 0.4231 - binary_accuracy: 0.8014 - val_loss: 0.4223 - val_binary_accuracy: 0.8021\n",
      "Epoch 35/100\n",
      "12651032/12651032 [==============================] - 329s 26us/step - loss: 0.4229 - binary_accuracy: 0.8015 - val_loss: 0.4215 - val_binary_accuracy: 0.8029\n",
      "Epoch 36/100\n",
      "12651032/12651032 [==============================] - 325s 26us/step - loss: 0.4226 - binary_accuracy: 0.8016 - val_loss: 0.4220 - val_binary_accuracy: 0.8022\n",
      "Epoch 37/100\n",
      "12651032/12651032 [==============================] - 324s 26us/step - loss: 0.4224 - binary_accuracy: 0.8017 - val_loss: 0.4225 - val_binary_accuracy: 0.8018\n",
      "Epoch 38/100\n",
      "12651032/12651032 [==============================] - 323s 26us/step - loss: 0.4222 - binary_accuracy: 0.8019 - val_loss: 0.4215 - val_binary_accuracy: 0.8026\n",
      "Epoch 39/100\n",
      "12651032/12651032 [==============================] - 324s 26us/step - loss: 0.4220 - binary_accuracy: 0.8020 - val_loss: 0.4225 - val_binary_accuracy: 0.8017\n",
      "Epoch 40/100\n",
      "12651032/12651032 [==============================] - 334s 26us/step - loss: 0.4218 - binary_accuracy: 0.8021 - val_loss: 0.4244 - val_binary_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "12651032/12651032 [==============================] - 309s 24us/step - loss: 0.4216 - binary_accuracy: 0.8021 - val_loss: 0.4207 - val_binary_accuracy: 0.8033\n",
      "Epoch 42/100\n",
      "12651032/12651032 [==============================] - 334s 26us/step - loss: 0.4214 - binary_accuracy: 0.8022 - val_loss: 0.4221 - val_binary_accuracy: 0.8022\n",
      "Epoch 43/100\n",
      "12651032/12651032 [==============================] - 326s 26us/step - loss: 0.4212 - binary_accuracy: 0.8023 - val_loss: 0.4229 - val_binary_accuracy: 0.8011\n",
      "Epoch 44/100\n",
      "12651032/12651032 [==============================] - 338s 27us/step - loss: 0.4211 - binary_accuracy: 0.8025 - val_loss: 0.4207 - val_binary_accuracy: 0.8031\n",
      "Epoch 45/100\n",
      "12651032/12651032 [==============================] - 331s 26us/step - loss: 0.4209 - binary_accuracy: 0.8025 - val_loss: 0.4213 - val_binary_accuracy: 0.8022\n",
      "Epoch 46/100\n",
      "12651032/12651032 [==============================] - 330s 26us/step - loss: 0.4207 - binary_accuracy: 0.8025 - val_loss: 0.4218 - val_binary_accuracy: 0.8009\n",
      "Epoch 47/100\n",
      "12651032/12651032 [==============================] - 312s 25us/step - loss: 0.4206 - binary_accuracy: 0.8027 - val_loss: 0.4201 - val_binary_accuracy: 0.8033\n",
      "Epoch 48/100\n",
      "12651032/12651032 [==============================] - 321s 25us/step - loss: 0.4204 - binary_accuracy: 0.8028 - val_loss: 0.4204 - val_binary_accuracy: 0.8026\n",
      "Epoch 49/100\n",
      "12651032/12651032 [==============================] - 315s 25us/step - loss: 0.4202 - binary_accuracy: 0.8028 - val_loss: 0.4202 - val_binary_accuracy: 0.8026\n",
      "Epoch 50/100\n",
      "12651032/12651032 [==============================] - 317s 25us/step - loss: 0.4201 - binary_accuracy: 0.8028 - val_loss: 0.4213 - val_binary_accuracy: 0.8023\n",
      "Epoch 51/100\n",
      "12651032/12651032 [==============================] - 324s 26us/step - loss: 0.4199 - binary_accuracy: 0.8031 - val_loss: 0.4195 - val_binary_accuracy: 0.8030\n",
      "Epoch 52/100\n",
      "12651032/12651032 [==============================] - 316s 25us/step - loss: 0.4197 - binary_accuracy: 0.8031 - val_loss: 0.4191 - val_binary_accuracy: 0.8031\n",
      "Epoch 53/100\n",
      "12651032/12651032 [==============================] - 322s 25us/step - loss: 0.4195 - binary_accuracy: 0.8032 - val_loss: 0.4189 - val_binary_accuracy: 0.8036\n",
      "Epoch 54/100\n",
      "12651032/12651032 [==============================] - 306s 24us/step - loss: 0.4193 - binary_accuracy: 0.8033 - val_loss: 0.4189 - val_binary_accuracy: 0.8037\n",
      "Epoch 55/100\n",
      "12651032/12651032 [==============================] - 327s 26us/step - loss: 0.4191 - binary_accuracy: 0.8034 - val_loss: 0.4190 - val_binary_accuracy: 0.8038\n",
      "Epoch 56/100\n",
      "12651032/12651032 [==============================] - 305s 24us/step - loss: 0.4189 - binary_accuracy: 0.8034 - val_loss: 0.4178 - val_binary_accuracy: 0.8039\n",
      "Epoch 57/100\n",
      "12651032/12651032 [==============================] - 330s 26us/step - loss: 0.4188 - binary_accuracy: 0.8035 - val_loss: 0.4179 - val_binary_accuracy: 0.8046\n",
      "Epoch 58/100\n",
      "12651032/12651032 [==============================] - 305s 24us/step - loss: 0.4185 - binary_accuracy: 0.8036 - val_loss: 0.4213 - val_binary_accuracy: 0.8011\n",
      "Epoch 59/100\n",
      "12651032/12651032 [==============================] - 325s 26us/step - loss: 0.4184 - binary_accuracy: 0.8037 - val_loss: 0.4180 - val_binary_accuracy: 0.8036\n",
      "Epoch 60/100\n",
      "12651032/12651032 [==============================] - 299s 24us/step - loss: 0.4182 - binary_accuracy: 0.8038 - val_loss: 0.4177 - val_binary_accuracy: 0.8042\n",
      "Epoch 61/100\n",
      "12651032/12651032 [==============================] - 326s 26us/step - loss: 0.4180 - binary_accuracy: 0.8039 - val_loss: 0.4180 - val_binary_accuracy: 0.8038\n",
      "Epoch 62/100\n",
      "12651032/12651032 [==============================] - 301s 24us/step - loss: 0.4179 - binary_accuracy: 0.8039 - val_loss: 0.4176 - val_binary_accuracy: 0.8035\n",
      "Epoch 63/100\n",
      "12651032/12651032 [==============================] - 324s 26us/step - loss: 0.4177 - binary_accuracy: 0.8041 - val_loss: 0.4185 - val_binary_accuracy: 0.8042\n",
      "Epoch 64/100\n",
      "12651032/12651032 [==============================] - 298s 24us/step - loss: 0.4175 - binary_accuracy: 0.8042 - val_loss: 0.4169 - val_binary_accuracy: 0.8052\n",
      "Epoch 65/100\n",
      "12651032/12651032 [==============================] - 341s 27us/step - loss: 0.4174 - binary_accuracy: 0.8043 - val_loss: 0.4165 - val_binary_accuracy: 0.8051\n",
      "Epoch 66/100\n",
      "12651032/12651032 [==============================] - 331s 26us/step - loss: 0.4171 - binary_accuracy: 0.8044 - val_loss: 0.4174 - val_binary_accuracy: 0.8051\n",
      "Epoch 67/100\n",
      "12651032/12651032 [==============================] - 337s 27us/step - loss: 0.4169 - binary_accuracy: 0.8046 - val_loss: 0.4160 - val_binary_accuracy: 0.8051\n",
      "Epoch 68/100\n",
      "12651032/12651032 [==============================] - 331s 26us/step - loss: 0.4166 - binary_accuracy: 0.8049 - val_loss: 0.4171 - val_binary_accuracy: 0.8053\n",
      "Epoch 69/100\n",
      "12651032/12651032 [==============================] - 302s 24us/step - loss: 0.4164 - binary_accuracy: 0.8050 - val_loss: 0.4164 - val_binary_accuracy: 0.8048\n",
      "Epoch 70/100\n",
      "12651032/12651032 [==============================] - 321s 25us/step - loss: 0.4163 - binary_accuracy: 0.8051 - val_loss: 0.4173 - val_binary_accuracy: 0.8047\n",
      "Epoch 71/100\n",
      "12651032/12651032 [==============================] - 298s 24us/step - loss: 0.4161 - binary_accuracy: 0.8051 - val_loss: 0.4173 - val_binary_accuracy: 0.8048\n",
      "Epoch 72/100\n",
      "12651032/12651032 [==============================] - 326s 26us/step - loss: 0.4160 - binary_accuracy: 0.8053 - val_loss: 0.4153 - val_binary_accuracy: 0.8058\n",
      "Epoch 73/100\n",
      "12651032/12651032 [==============================] - 328s 26us/step - loss: 0.4158 - binary_accuracy: 0.8053 - val_loss: 0.4173 - val_binary_accuracy: 0.8047\n",
      "Epoch 74/100\n",
      "12651032/12651032 [==============================] - 326s 26us/step - loss: 0.4157 - binary_accuracy: 0.8054 - val_loss: 0.4167 - val_binary_accuracy: 0.8052\n",
      "Epoch 75/100\n",
      "12651032/12651032 [==============================] - 306s 24us/step - loss: 0.4155 - binary_accuracy: 0.8055 - val_loss: 0.4229 - val_binary_accuracy: 0.8004\n",
      "Epoch 76/100\n",
      "12651032/12651032 [==============================] - 337s 27us/step - loss: 0.4154 - binary_accuracy: 0.8056 - val_loss: 0.4148 - val_binary_accuracy: 0.8064\n",
      "Epoch 77/100\n",
      "12651032/12651032 [==============================] - 329s 26us/step - loss: 0.4152 - binary_accuracy: 0.8057 - val_loss: 0.4146 - val_binary_accuracy: 0.8061\n",
      "Epoch 78/100\n",
      "12651032/12651032 [==============================] - 321s 25us/step - loss: 0.4151 - binary_accuracy: 0.8058 - val_loss: 0.4145 - val_binary_accuracy: 0.8065\n",
      "Epoch 79/100\n",
      "12651032/12651032 [==============================] - 318s 25us/step - loss: 0.4150 - binary_accuracy: 0.8059 - val_loss: 0.4158 - val_binary_accuracy: 0.8050\n",
      "Epoch 80/100\n",
      "12651032/12651032 [==============================] - 339s 27us/step - loss: 0.4149 - binary_accuracy: 0.8059 - val_loss: 0.4145 - val_binary_accuracy: 0.8056\n",
      "Epoch 81/100\n",
      "12651032/12651032 [==============================] - 346s 27us/step - loss: 0.4147 - binary_accuracy: 0.8060 - val_loss: 0.4143 - val_binary_accuracy: 0.8064\n",
      "Epoch 82/100\n",
      "12651032/12651032 [==============================] - 337s 27us/step - loss: 0.4146 - binary_accuracy: 0.8061 - val_loss: 0.4152 - val_binary_accuracy: 0.8053\n",
      "Epoch 83/100\n",
      "12651032/12651032 [==============================] - 336s 27us/step - loss: 0.4145 - binary_accuracy: 0.8063 - val_loss: 0.4136 - val_binary_accuracy: 0.8072\n",
      "Epoch 84/100\n",
      "12651032/12651032 [==============================] - 344s 27us/step - loss: 0.4144 - binary_accuracy: 0.8063 - val_loss: 0.4136 - val_binary_accuracy: 0.8069\n",
      "Epoch 85/100\n",
      "12651032/12651032 [==============================] - 348s 27us/step - loss: 0.4143 - binary_accuracy: 0.8063 - val_loss: 0.4138 - val_binary_accuracy: 0.8071\n",
      "Epoch 86/100\n",
      "12651032/12651032 [==============================] - 376s 30us/step - loss: 0.4142 - binary_accuracy: 0.8063 - val_loss: 0.4148 - val_binary_accuracy: 0.8068\n",
      "Epoch 87/100\n",
      "12651032/12651032 [==============================] - 326s 26us/step - loss: 0.4141 - binary_accuracy: 0.8064 - val_loss: 0.4147 - val_binary_accuracy: 0.8061\n",
      "Epoch 88/100\n",
      "12651032/12651032 [==============================] - 319s 25us/step - loss: 0.4139 - binary_accuracy: 0.8065 - val_loss: 0.4140 - val_binary_accuracy: 0.8074\n",
      "Epoch 89/100\n",
      "12651032/12651032 [==============================] - 331s 26us/step - loss: 0.4139 - binary_accuracy: 0.8065 - val_loss: 0.4134 - val_binary_accuracy: 0.8069\n",
      "Epoch 90/100\n",
      "12651032/12651032 [==============================] - 327s 26us/step - loss: 0.4137 - binary_accuracy: 0.8067 - val_loss: 0.4148 - val_binary_accuracy: 0.8063\n",
      "Epoch 91/100\n",
      "12651032/12651032 [==============================] - 335s 26us/step - loss: 0.4136 - binary_accuracy: 0.8068 - val_loss: 0.4136 - val_binary_accuracy: 0.8067\n",
      "Epoch 92/100\n",
      "12651032/12651032 [==============================] - 327s 26us/step - loss: 0.4136 - binary_accuracy: 0.8068 - val_loss: 0.4133 - val_binary_accuracy: 0.8072\n",
      "Epoch 93/100\n",
      "12651032/12651032 [==============================] - 317s 25us/step - loss: 0.4134 - binary_accuracy: 0.8069 - val_loss: 0.4130 - val_binary_accuracy: 0.8078\n",
      "Epoch 94/100\n",
      "12651032/12651032 [==============================] - 324s 26us/step - loss: 0.4133 - binary_accuracy: 0.8070 - val_loss: 0.4130 - val_binary_accuracy: 0.8073\n",
      "Epoch 95/100\n",
      "12651032/12651032 [==============================] - 316s 25us/step - loss: 0.4132 - binary_accuracy: 0.8070 - val_loss: 0.4125 - val_binary_accuracy: 0.8072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "12651032/12651032 [==============================] - 322s 25us/step - loss: 0.4131 - binary_accuracy: 0.8071 - val_loss: 0.4119 - val_binary_accuracy: 0.8083\n",
      "Epoch 97/100\n",
      "12651032/12651032 [==============================] - 335s 27us/step - loss: 0.4130 - binary_accuracy: 0.8072 - val_loss: 0.4131 - val_binary_accuracy: 0.8070\n",
      "Epoch 98/100\n",
      "12651032/12651032 [==============================] - 330s 26us/step - loss: 0.4129 - binary_accuracy: 0.8072 - val_loss: 0.4117 - val_binary_accuracy: 0.8084\n",
      "Epoch 99/100\n",
      "12651032/12651032 [==============================] - 321s 25us/step - loss: 0.4128 - binary_accuracy: 0.8073 - val_loss: 0.4119 - val_binary_accuracy: 0.8086\n",
      "Epoch 100/100\n",
      "12651032/12651032 [==============================] - 323s 25us/step - loss: 0.4127 - binary_accuracy: 0.8073 - val_loss: 0.4135 - val_binary_accuracy: 0.8063\n",
      "3515821/3515821 [==============================] - 150s 43us/step\n",
      "Loss and Accuracy:  0.4154681283438333 0.8052321207479332\n",
      "precision: [0.8289027  0.75856642]\n",
      "recall: [0.8712756  0.69219936]\n",
      "fscore: [0.84956113 0.72386487]\n",
      "support: [2219183 1296638]\n",
      "Predicted      0.0      1.0      All\n",
      "True                                \n",
      "0          1933520   285663  2219183\n",
      "1           399106   897532  1296638\n",
      "All        2332626  1183195  3515821\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "import pickle \n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    " # Read X_final and Y_final\n",
    "with open('X_final8020.pickle', 'rb') as handle:\n",
    "    X_final = pickle.load(handle)\n",
    "\n",
    "with open('Y_final8020.pickle', 'rb') as handle:\n",
    "    Y_final = pickle.load(handle)\n",
    "\n",
    " # Read X_test and Y_test\n",
    "with open('X_test8020.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "\n",
    "with open('Y_test8020.pickle', 'rb') as handle:\n",
    "    Y_test = pickle.load(handle)\n",
    "\n",
    "input_length    = X_final.shape[1]\n",
    "input_dim       = X_final.shape[2]\n",
    "output_dim      = len(Y_final[0])\n",
    "\n",
    "# Model 1\n",
    "\n",
    "def create_model1(input_dim = input_dim, input_length = input_length, output_dim=output_dim):\n",
    "    print ('Creating model 1...')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(20))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "    print ('Compiling...')\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model       = create_model1()\n",
    "history     = model.fit(X_final,Y_final,batch_size=250, epochs=100, validation_split = 0.10, verbose = 1)\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print('Loss and Accuracy: ', loss, accuracy)\n",
    "y_pred      = model.predict(X_test)\n",
    "y_true      = pd.Series([x[0] for x in Y_test])\n",
    "y_predicted = pd.Series([ np.rint(j[0]) for j in y_pred])\n",
    "\n",
    "precision, recall, fscore, support = score(y_true, y_predicted)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "#Save\n",
    "model.save('model1_8020split.keras')\n",
    "\n",
    "print(pd.crosstab(y_true, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "################# End of Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store in lstm / testtraindata[80-20] / timestep1_no_jobgroups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
