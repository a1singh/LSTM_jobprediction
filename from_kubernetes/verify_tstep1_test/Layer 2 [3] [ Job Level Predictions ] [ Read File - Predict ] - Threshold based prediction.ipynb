{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "path                 = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX 1 of 3 : set the following vars\n",
    "path                 = \".\" #path to dir where test pickles reside and h5 file is\n",
    "modelfingerprint     = \"kubernetes_train_[80-20]_giga_long_mltithrdedgentr_PikTranSav_Mdl_[J_Filternet_tstep1]_epch_75_kube_binar_crsentr_adm_binar_acc.py\" # name of py file\n",
    "modelweightsfilename = \"kubernetes_train_[80-20]_giga_long_mltithrdedgentr_PikTranSav_Mdl_[J_Filternet_tstep1]_epch_75_kube_binar_crsentr_adm_binar_acc.h5\" # name of h5 file\n",
    "\n",
    "# FIX 2 of 3: update the input_length as per timesteps\n",
    "input_length    = 1 # 1 or 2                        # X_final.shape[1]\n",
    "input_dim       = 3541                              # X_final.shape[2]\n",
    "output_dim      = 1\n",
    "\n",
    "pickgpus = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = pickgpus\n",
    "\n",
    "def create_model(input_dim, input_length, output_dim):\n",
    "    print ('Creating model...')\n",
    "    # FIX 3 of 3: copy everything from here till 'return parallel_model'\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(2000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(2000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(1000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(2000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(2000))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "    ###\n",
    "    print('Initiating parallel GPU model')\n",
    "    parallel_model = multi_gpu_model(model, gpus=1+pickgpus.count(\",\"))\n",
    "    print ('Compiling...')\n",
    "    parallel_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['binary_accuracy'])\n",
    "    return parallel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "model   = create_model(input_dim, input_length, output_dim)\n",
    "# STEP 2\n",
    "print('Loading Model weights before Testing')\n",
    "model.load_weights( join(path, modelweightsfilename) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm up\n",
    "warmup=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "test_files = [x for x in test_files if 'dict_jobID_' in x and 'FROM_giga_takeoutdf_w_jobgroup.pickle' in x ]\n",
    "test_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def chunked(it, size):\n",
    "    it = iter(it)\n",
    "    while True:\n",
    "        p = tuple(itertools.islice(it, size))\n",
    "        if not p:\n",
    "            break\n",
    "        yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "from threading import Lock\n",
    "lock               = Lock()\n",
    "\n",
    "def h(jobID_Xtest_Ytest):\n",
    "    global model\n",
    "    global lock\n",
    "    \n",
    "    Y_true = []\n",
    "    Y_pred = []\n",
    "    jobID, X_test, Y_test     = jobID_Xtest_Ytest[0], jobID_Xtest_Ytest[1][0], jobID_Xtest_Ytest[1][1]         \n",
    "    try:\n",
    "        lock.acquire()\n",
    "        y_pred_this_file = model.predict(X_test)\n",
    "    finally:\n",
    "        lock.release()\n",
    "    \n",
    "    Y_pred.extend([ np.rint(jj[0]) for jj in y_pred_this_file ])\n",
    "    Y_true.extend([ xj[0] for xj in Y_test ])\n",
    "    \n",
    "    #test 1\n",
    "    if not all(x == Y_true[0] for x in Y_true):\n",
    "        print('All Y_true labels for jobID %d are not same \\n' % jobID)\n",
    "    \n",
    "    return [jobID, Y_true, Y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stage_results = []\n",
    "import random\n",
    "\n",
    "for k in range(len(test_files)):\n",
    "    # Load { jobID -> X_test, Y_test }:\n",
    "    print( \"Loading test file #%d - %s\" % (k, test_files[k]) )\n",
    "    with open( join(path, test_files[k]) , 'rb' ) as handle:\n",
    "        global_dict = pickle.load(handle)\n",
    "    print( \"Loaded test file #%d\" % (len(global_dict))       )\n",
    "    \n",
    "    # warm up\n",
    "    if(warmup):\n",
    "        print(model.predict(random.choice(list(global_dict.items()))[1][0]))\n",
    "        warmup=False\n",
    "        \n",
    "    start = 1\n",
    "    for chunk in chunked(global_dict.items(), 48*5):\n",
    "        print(\"New Batch started : %d to %d \" % (start, start+len(chunk)-1))\n",
    "        results = Parallel(n_jobs=48, verbose=1, backend=\"threading\")(map(delayed(h), [x for x in chunk] ))\n",
    "        stage_results.extend(results)\n",
    "        del results\n",
    "        start += len(chunk)\n",
    "    del global_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stage_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('stage_results_list_of_jobid_x_y_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(stage_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predicted 'heartbeat' level results into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stage_results_list_of_jobid_x_y_test.pickle', 'rb') as handle:\n",
    "    stage_results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(listelement_parameters):\n",
    "    listelement = listelement_parameters[0]\n",
    "    parameters  = listelement_parameters[1]\n",
    "    \n",
    "    # each input: listelement is [jobID, Y_true, Y_pred]\n",
    "    # make job level prediction, based on parameters\n",
    "    decision_threshold = parameters[0]\n",
    "    minsamplestopick   = parameters[1]\n",
    "    maxsamplestopick   = parameters[2]\n",
    "    \n",
    "    ###\n",
    "    jobID  = listelement[0]\n",
    "    Y_true = listelement[1]\n",
    "    Y_pred = listelement[2]\n",
    "    \n",
    "    truelabel = Y_true[0]\n",
    "    \n",
    "    # perform job-level prediction in a while loop:\n",
    "    firstN           = min( minsamplestopick, len(Y_pred) )\n",
    "    localsamplefrac  = (firstN*1.0) / len(Y_pred)\n",
    "    localsamplefracN = localsamplefrac\n",
    "    predictedlabel   = -1\n",
    "    \n",
    "    ##### Method: take majority\n",
    "    while predictedlabel == -1 and firstN <= min(maxsamplestopick, len(Y_pred)):\n",
    "        #\n",
    "        localsamplefrac = (firstN*1.0) / len(Y_pred)\n",
    "        \n",
    "        ############################################################\n",
    "        take            = Y_pred[:firstN]\n",
    "        ############################################################\n",
    "        \n",
    "        if take.count(1.0) > int(decision_threshold * len(take)):\n",
    "            predictedlabel = 1\n",
    "            break\n",
    "            \n",
    "        if take.count(0.0) > int(decision_threshold * len(take)):\n",
    "            predictedlabel = 0\n",
    "            break\n",
    "        \n",
    "        firstN          =  firstN + 1\n",
    "    \n",
    "    # create a python list that will be return\n",
    "    \n",
    "    totaljobduration   = 1.0\n",
    "    predictionduration = -1.0\n",
    "    return [jobID, totaljobduration, predictionduration, \n",
    "            localsamplefrac, len(Y_true), decision_threshold, \n",
    "            truelabel, predictedlabel]\n",
    "\n",
    "    ###################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4800)]: Done 200 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4800)]: Done 1650 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4800)]: Done 3200 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4800)]: Done 4850 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4800)]: Done 6600 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4800)]: Done 8450 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4800)]: Done 10400 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4800)]: Done 12450 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4800)]: Done 14600 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4800)]: Done 16850 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4800)]: Done 19200 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4800)]: Done 21650 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4800)]: Done 24200 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4800)]: Done 26850 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=4800)]: Done 29600 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=4800)]: Done 32450 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4800)]: Done 35400 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=4800)]: Done 38450 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=4800)]: Done 41600 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4800)]: Done 44850 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=4800)]: Done 48200 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=4800)]: Done 51650 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4800)]: Done 55200 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=4800)]: Done 58850 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4800)]: Done 62600 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=4800)]: Done 66450 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=4800)]: Done 70400 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=4800)]: Done 74450 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=4800)]: Done 78600 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=4800)]: Done 82850 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=4800)]: Done 87200 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=4800)]: Done 91650 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=4800)]: Done 96200 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=4800)]: Done 100850 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=4800)]: Done 105600 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=4800)]: Done 110450 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=4800)]: Done 115400 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=4800)]: Done 120450 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=4800)]: Done 125600 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=4800)]: Done 130850 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=4800)]: Done 136200 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=4800)]: Done 141650 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=4800)]: Done 147200 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=4800)]: Done 152850 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=4800)]: Done 158600 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=4800)]: Done 164450 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=4800)]: Done 170400 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=4800)]: Done 176450 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=4800)]: Done 182600 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=4800)]: Done 188850 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=4800)]: Done 195200 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=4800)]: Done 201650 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=4800)]: Done 208200 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=4800)]: Done 214850 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=4800)]: Done 221600 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=4800)]: Done 228450 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=4800)]: Done 235400 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4800)]: Done 242450 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4800)]: Done 249600 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4800)]: Done 256850 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4800)]: Done 264200 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4800)]: Done 271650 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4800)]: Done 279200 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4800)]: Done 286850 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4800)]: Done 294600 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4800)]: Done 302450 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4800)]: Done 310400 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4800)]: Done 320730 out of 320730 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 1min 33s, total: 3min 14s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parameters   = [ decision_threshold, minsamplestopick, maxsamplestopick ]\n",
    "parameters     = [ 0.95              , 3               ,20]\n",
    "inputList      = [ [x, parameters] for x in stage_results ]\n",
    "global_results = Parallel(n_jobs=48*100, verbose=1, backend=\"threading\")(map(delayed(process), inputList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate totalduration and predictionduration\n",
    "with open('giga_takeoutdf_w_jobgroup.pickle', 'rb') as f:\n",
    "    takeoutdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_durations(row):\n",
    "    # Input format:\n",
    "    # [jobID, totaljobduration, predictionduration,localsamplefrac, len(Y_true), decision_threshold,truelabel, predictedlabel]\n",
    "    \n",
    "    jobID      = row[0]\n",
    "    firstN     = int(row[3]*row[4])\n",
    "\n",
    "    # Sort by timestamp\n",
    "    getsamples = takeoutdf[takeoutdf.JobID == jobID]\n",
    "    df         = getsamples.sort_values(by=['HeartBeatTime']) #not inplace\n",
    "    hlist      = df['HeartBeatTime'].tolist()\n",
    "    \n",
    "    starttime     = hlist[0]\n",
    "    predictedtime = hlist[firstN-1]\n",
    "    endtime       = hlist[row[4]-1]\n",
    "    \n",
    "    row[1]= (endtime-starttime).total_seconds()       #totaljobduration\n",
    "    row[2]= (predictedtime-starttime).total_seconds() #predictionduration\n",
    "    \n",
    "    return jobID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=240)]: Done 320 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=240)]: Done 770 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=240)]: Done 1320 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=240)]: Done 1970 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=240)]: Done 2720 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=240)]: Done 3570 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=240)]: Done 4520 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=240)]: Done 5570 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=240)]: Done 6720 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=240)]: Done 7970 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=240)]: Done 9320 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=240)]: Done 10770 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=240)]: Done 12320 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=240)]: Done 13970 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=240)]: Done 15720 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=240)]: Done 17570 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=240)]: Done 19520 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=240)]: Done 21570 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=240)]: Done 23720 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=240)]: Done 25970 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=240)]: Done 28320 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=240)]: Done 30770 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=240)]: Done 33320 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=240)]: Done 35970 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=240)]: Done 38720 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=240)]: Done 41570 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=240)]: Done 44520 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=240)]: Done 47570 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=240)]: Done 50720 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=240)]: Done 53970 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=240)]: Done 57320 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=240)]: Done 60770 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=240)]: Done 64320 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=240)]: Done 67970 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=240)]: Done 71720 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=240)]: Done 75570 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=240)]: Done 79520 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=240)]: Done 83570 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=240)]: Done 87720 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=240)]: Done 91970 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=240)]: Done 96320 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=240)]: Done 100770 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=240)]: Done 105320 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=240)]: Done 109970 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=240)]: Done 114720 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=240)]: Done 119570 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=240)]: Done 124520 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=240)]: Done 129570 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=240)]: Done 134720 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=240)]: Done 139970 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=240)]: Done 145320 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=240)]: Done 150770 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=240)]: Done 156320 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=240)]: Done 161970 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=240)]: Done 167720 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=240)]: Done 173570 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=240)]: Done 179520 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=240)]: Done 185570 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=240)]: Done 191720 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=240)]: Done 197970 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=240)]: Done 204320 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=240)]: Done 210770 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=240)]: Done 217320 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=240)]: Done 223970 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=240)]: Done 230720 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=240)]: Done 237570 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=240)]: Done 244520 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=240)]: Done 251570 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=240)]: Done 258720 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=240)]: Done 265970 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=240)]: Done 273320 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=240)]: Done 280770 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=240)]: Done 288320 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=240)]: Done 295970 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=240)]: Done 303720 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=240)]: Done 311570 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=240)]: Done 319520 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=240)]: Done 320730 out of 320730 | elapsed: 11.6min finished\n"
     ]
    }
   ],
   "source": [
    "# update times in the results\n",
    "collector = Parallel(n_jobs=48*5, verbose=1, backend=\"threading\")(map(delayed(fill_durations), global_results ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results:\n",
    "\n",
    "Y_true_job      = []\n",
    "Y_predicted_job = []\n",
    "averagefrac     = []\n",
    "nodecision      = []\n",
    "averagetime     = []\n",
    "totaltestsamples= 0\n",
    "\n",
    "for r in global_results:\n",
    "    ###\n",
    "    totaltestsamples += r[4]\n",
    "    ###\n",
    "    \n",
    "    if r[-1] != -1:\n",
    "        Y_true_job.append(r[-2])\n",
    "        Y_predicted_job.append(r[-1])\n",
    "        averagefrac.append(r[3])      #based on no of samples used for prediction\n",
    "        \n",
    "        if r[1] !=0:    #totaljobduration - total jobduration\n",
    "            averagetime.append(r[2]/r[1]) #based on time of prediction\n",
    "        elif r[2] == 0: #predictionduration - job duration at time of prediction\n",
    "            averagetime.append(1)\n",
    "        else:\n",
    "            print('Error: predictionduration=%.2f, totaljobduration=%.2f ' % (r[2], r[1]))\n",
    "    else:\n",
    "        nodecision.append(r)\n",
    "\n",
    "# [jobID, totaljobduration, predictionduration,localsamplefrac, len(Y_true), decision_threshold,truelabel, predictedlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of Y_true :  308448\n",
      "Len of Y_pred :  308448\n",
      "Overall accuracy on test set:  0.8493814192343604\n",
      "Calculating Score: \n",
      "precision    : [0.82966041 0.87564062]\n",
      "recall       : [0.89881919 0.79426526]\n",
      "fscore       : [0.86285623 0.83297021]\n",
      "support      : [162600 145848]\n",
      "Confusion matrix:\n",
      "Predicted       0       1     All\n",
      "True                             \n",
      "0          146148   16452  162600\n",
      "1           30006  115842  145848\n",
      "All        176154  132294  308448\n",
      "*********Test Results End**************\n"
     ]
    }
   ],
   "source": [
    "print('Len of Y_true : ', len(Y_true_job))\n",
    "print('Len of Y_pred : ', len(Y_predicted_job))\n",
    "\n",
    "print(\"Overall accuracy on test set: \", np.mean(np.equal(Y_true_job, Y_predicted_job)))\n",
    "\n",
    "print(\"Calculating Score: \")\n",
    "precision, recall, fscore, support = score(Y_true_job, Y_predicted_job)\n",
    "print('precision    : {}'.format(precision))\n",
    "print('recall       : {}'.format(recall))\n",
    "print('fscore       : {}'.format(fscore))\n",
    "print('support      : {}'.format(support))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(pd.Series(Y_true_job), pd.Series(Y_predicted_job), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print('*********Test Results End**************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5439598882165064, 0.5039671829113419)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(averagefrac), np.mean(averagetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12282, 320730, 0.038293892058740994)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodecision), len(Y_true_job)+len(nodecision),  len(nodecision)/(len(Y_true_job)+len(nodecision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308448"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(averagetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3517991"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totaltestsamples #for verification (should be 3,517,991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "\n",
    "for x in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
