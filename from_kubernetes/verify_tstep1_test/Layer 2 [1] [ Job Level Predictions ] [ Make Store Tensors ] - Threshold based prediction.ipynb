{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giga_takeoutdf_w_jobgroup.pickle\n",
    "import pickle\n",
    "with open('giga_takeoutdf_w_jobgroup.pickle', 'rb') as f:\n",
    "    takeoutdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giga_training_features_w_jobgroup.pickle\n",
    "with open('giga_training_features_w_jobgroup.pickle', 'rb') as f:\n",
    "    training_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = set(takeoutdf.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = set(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HeartBeatTime',\n",
       " 'JobID',\n",
       " 'RescheduleCounter',\n",
       " 'Status_Failed',\n",
       " 'WallClockTime'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1-l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "setofjobids = set(takeoutdf['JobID'].tolist())\n",
    "listofjobids= list(setofjobids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_grouped = takeoutdf.groupby(['JobID']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedjobids = df_grouped[df_grouped.counts>min_samples].JobID.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320730, 320730)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selectedjobids), len(listofjobids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX 1 of 3 : set the following vars\n",
    "path                 = \".\" #path to dir where test pickles reside and h5 file is\n",
    "modelfingerprint     = \"kubernetes_train_[80-20]_giga_long_mltithrdedgentr_PikTranSav_Mdl_[J_Filternet_tstep1]_epch_75_kube_binar_crsentr_adm_binar_acc.py\" # name of py file\n",
    "modelweightsfilename = \"kubernetes_train_[80-20]_giga_long_mltithrdedgentr_PikTranSav_Mdl_[J_Filternet_tstep1]_epch_75_kube_binar_crsentr_adm_binar_acc.h5\" # name of h5 file\n",
    "\n",
    "# FIX 2 of 3: update the input_length as per timesteps\n",
    "input_length    = 1 # 1 or 2                        # X_final.shape[1]\n",
    "input_dim       = 3541                              # X_final.shape[2]\n",
    "output_dim      = 1\n",
    "\n",
    "pickgpus = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = pickgpus\n",
    "\n",
    "def create_model(input_dim, input_length, output_dim):\n",
    "    print ('Creating model...')\n",
    "    # FIX 3 of 3: copy everything from here till 'return parallel_model'\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(2000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(2000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(1000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(2000, input_shape=(input_length,input_dim),return_sequences=True))\n",
    "    model.add(LSTM(2000))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "    ###\n",
    "    print('Initiating parallel GPU model')\n",
    "    parallel_model = multi_gpu_model(model, gpus=1+pickgpus.count(\",\"))\n",
    "    print ('Compiling...')\n",
    "    parallel_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['binary_accuracy'])\n",
    "    return parallel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Initiating parallel GPU model\n",
      "Compiling...\n",
      "Loading Model weights before Testing\n"
     ]
    }
   ],
   "source": [
    "# STEP 1\n",
    "model   = create_model(input_dim, input_length, output_dim)\n",
    "# STEP 2\n",
    "print('Loading Model weights before Testing')\n",
    "model.load_weights( join(path, modelweightsfilename) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyParallel(dfGrouped, func):\n",
    "    #removed the parallel part since \n",
    "    #parallelism is at higher level - at jobID level\n",
    "    retLst = []\n",
    "    \n",
    "    for name, group in dfGrouped:\n",
    "        retLst.append(func(group))\n",
    "                                   \n",
    "    return retLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('giga_training_features_w_jobgroup.pickle', 'rb') as handle:\n",
    "    train_feat = pickle.load(handle)\n",
    "    \n",
    "label_col  = ['Status_Failed']\n",
    "thresholdd = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_label(df_input):\n",
    "    # \n",
    "    k = thresholdd\n",
    "    input_cols = label_col\n",
    "    \n",
    "    # takes a df\n",
    "    # Put your inputs into a single list\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['single_input_vector'] = df_input[input_cols].apply(tuple, axis=1).apply(list)\n",
    "    \n",
    "    # Double-encapsulate list so that you can sum it in the next step and keep time steps as separate elements\n",
    "    df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])\n",
    "        \n",
    "    # The starting point\n",
    "    df['cumulative_input_vectors'] = df['single_input_vector'].shift(0)\n",
    "    \n",
    "    for i in range(1,k):\n",
    "        df['cumulative_input_vectors'] += df['single_input_vector'].shift(i)\n",
    "          \n",
    "    df.dropna(inplace=True)     # does operation in place & returns None\n",
    "\n",
    "    # Extract your training data\n",
    "    X_ = np.asarray(df.cumulative_input_vectors)\n",
    "    \n",
    "    # Use hstack to and reshape to make the inputs a 3d vector\n",
    "    X = np.vstack(X_).reshape(len(df), k, len(input_cols))\n",
    "    \n",
    "    # Clean up\n",
    "    del df\n",
    "    \n",
    "    return X\n",
    "    # returns 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_features(df_input):\n",
    "    # \n",
    "    k = thresholdd\n",
    "    input_cols = train_feat\n",
    "    \n",
    "    # takes a df\n",
    "    # Put your inputs into a single list\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['single_input_vector'] = df_input[input_cols].apply(tuple, axis=1).apply(list)\n",
    "    \n",
    "    # Double-encapsulate list so that you can sum it in the next step and keep time steps as separate elements\n",
    "    df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])\n",
    "        \n",
    "    # The starting point\n",
    "    df['cumulative_input_vectors'] = df['single_input_vector'].shift(0)\n",
    "    \n",
    "    for i in range(1,k):\n",
    "        df['cumulative_input_vectors'] += df['single_input_vector'].shift(i)\n",
    "          \n",
    "    df.dropna(inplace=True)     # does operation in place & returns None\n",
    "\n",
    "    # Extract your training data\n",
    "    X_ = np.asarray(df.cumulative_input_vectors)\n",
    "    \n",
    "    # Use hstack to and reshape to make the inputs a 3d vector\n",
    "    X = np.vstack(X_).reshape(len(df), k, len(input_cols))\n",
    "    \n",
    "    # Clean up\n",
    "    del df\n",
    "    \n",
    "    return X\n",
    "    # returns 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock\n",
    "\n",
    "def createtensor(df):\n",
    "    #\n",
    "    cleanedgrouped = df.groupby('JobID')\n",
    "    # print('Collectrain started...')\n",
    "    collecttrain   = applyParallel(cleanedgrouped, samples_features)\n",
    "\n",
    "    #\n",
    "    X = []\n",
    "    for x in collecttrain:\n",
    "        #len(x)\n",
    "        for i in x:\n",
    "            X.append(i)\n",
    "    del collecttrain\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # print('Collectlabel started...')\n",
    "    collectlabel = applyParallel(cleanedgrouped, samples_label)\n",
    "    del cleanedgrouped\n",
    "\n",
    "    Y=[]\n",
    "    for x in collectlabel:\n",
    "        #len(x)\n",
    "        for i in x:\n",
    "            Y.append(i)\n",
    "    del collectlabel\n",
    "    \n",
    "    Y  = np.array(Y)\n",
    "    YY = np.array([x[0][0] for x in Y]).reshape(len(Y),1)\n",
    "    # \n",
    "    X_test, Y_test = X,YY # no shuffling in test set\n",
    "    #\n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "samplefrac         = 0.1\n",
    "decision_threshold = 0.95\n",
    "minsamplestopick   = 3\n",
    "lock               = Lock()\n",
    "global_dict = {}\n",
    "\n",
    "def g(jobID):\n",
    "    global model\n",
    "    global samplefrac\n",
    "    global global_dict\n",
    "    global lock\n",
    "    global takeoutdf\n",
    "    global minsamplestopick\n",
    "    \n",
    "    localsamplefrac = samplefrac\n",
    "    Y_true = []\n",
    "    Y_pred = []\n",
    "    #\n",
    "    #\n",
    "    # Sort by timestamp\n",
    "    getsamples = takeoutdf[takeoutdf.JobID == jobID].copy(deep=True)\n",
    "    df         = getsamples.sort_values(by=['HeartBeatTime'])\n",
    "    \n",
    "    # create 1 timestep 3D tensor\n",
    "    \n",
    "    X_test, Y_test     = createtensor(df)\n",
    "    del df\n",
    "    del getsamples\n",
    "    global_dict[jobID] = [X_test, Y_test]\n",
    "    \n",
    "    # model is global\n",
    "    \n",
    "    # get prediction on each timestep\n",
    "    \n",
    "    try:\n",
    "        lock.acquire()\n",
    "        y_pred_this_file = model.predict(X_test)\n",
    "    finally:\n",
    "        lock.release()\n",
    "    \n",
    "    Y_pred.extend([ np.rint(jj[0]) for jj in y_pred_this_file ])\n",
    "    Y_true.extend([ xj[0] for xj in Y_test ])\n",
    "    \n",
    "    #test 1\n",
    "    if not all(x == Y_true[0] for x in Y_true):\n",
    "        print('All Y_true labels for jobID %d are not same \\n' % jobID)\n",
    "\n",
    "    truelabel = Y_true[0]\n",
    "    \n",
    "    # perform job-level prediction in a while loop:\n",
    "    firstN         = min( max(minsamplestopick, int(localsamplefrac * len(Y_true))), len(Y_pred) )\n",
    "    predictedlabel = -1\n",
    "    \n",
    "    while(predictedlabel == -1 and localsamplefrac <= 1.0):\n",
    "        localsamplefrac = (firstN*1.0) / len(Y_pred)\n",
    "        take            = Y_pred[:firstN]\n",
    "        \n",
    "        if take.count(1.0) > decision_threshold * len(take):\n",
    "            predictedlabel = 1\n",
    "            break\n",
    "            \n",
    "        if take.count(0.0) > decision_threshold * len(take):\n",
    "            predictedlabel = 0\n",
    "            break\n",
    "        \n",
    "        firstN          = firstN + 1\n",
    "        \n",
    "    \n",
    "    # create a python list that will be return\n",
    "    # send back\n",
    "    totaljobduration   = None\n",
    "    predictionduration = None\n",
    "     \n",
    "    return [jobID, totaljobduration, predictionduration, localsamplefrac, len(Y_true), decision_threshold, truelabel, predictedlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320730, 320730)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selectedjobids), len(listofjobids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23141083, None, None, 1.0, 1, 0.95, 1, 1]\n",
      "[23205649, None, None, 0.13043478260869565, 23, 0.95, 1, 1]\n",
      "[23205658, None, None, 0.15789473684210525, 19, 0.95, 1, 1]\n",
      "[23205662, None, None, 0.11538461538461539, 26, 0.95, 1, 1]\n",
      "[23205666, None, None, 0.13636363636363635, 22, 0.95, 1, 1]\n",
      "[23205667, None, None, 0.14285714285714285, 21, 0.95, 1, 1]\n",
      "[23205673, None, None, 0.15789473684210525, 19, 0.95, 1, 1]\n",
      "[23205675, None, None, 0.11538461538461539, 26, 0.95, 1, 1]\n",
      "[23205692, None, None, 0.16666666666666666, 18, 0.95, 1, 1]\n",
      "[23205742, None, None, 0.15, 20, 0.95, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# warm up\n",
    "# https://github.com/keras-team/keras/issues/6124\n",
    "# Keras builds the GPU function the first time you call predict().\n",
    "\n",
    "for x in selectedjobids[:10]:\n",
    "    print(g(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(selectedjobids)\n",
    "breakeachinto  = 30\n",
    "global_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 160365 to 171055 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 171056 to 181746 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 181747 to 192437 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 192438 to 203128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 203129 to 213819 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 213820 to 224510 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 224511 to 235201 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 235202 to 245892 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 245893 to 256583 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 256584 to 267274 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 267275 to 277965 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 277966 to 288656 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 288657 to 299347 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 299348 to 310038 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Batch started : 310039 to 320729 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=48)]: Done 4904 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=48)]: Done 5954 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=48)]: Done 7104 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=48)]: Done 8354 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=48)]: Done 9704 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=48)]: Done 10691 out of 10691 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 21min 19s, sys: 21min 33s, total: 3h 42min 53s\n",
      "Wall time: 2h 42min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gc\n",
    "\n",
    "# Test in batches:\n",
    "\n",
    "for bat in batch([x for x in range(160365, length)], int(length/breakeachinto)):\n",
    "    global_dict = {}\n",
    "    \n",
    "    print(\"New Batch started : %d to %d \" % (bat[0], bat[-1]))\n",
    "    results = Parallel(n_jobs=48, verbose=1, backend=\"threading\")(map(delayed(g), [selectedjobids[i] for i in bat] ))\n",
    "    global_results.extend(results)\n",
    "    del results\n",
    "    \n",
    "    # save dict to disk\n",
    "    start    = bat[0]\n",
    "    end      = bat[-1]\n",
    "    filename = 'dict_jobID_Xtest_Ytest_'+str(start)+'_'+str(end)+'_FROM_giga_takeoutdf_w_jobgroup.pickle'\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(global_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    del global_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_job      = []\n",
    "Y_predicted_job = []\n",
    "averagefrac     = []\n",
    "nodecision      = []\n",
    "\n",
    "for r in global_results:\n",
    "    if r[-1] != -1:\n",
    "        Y_true_job.append(r[-2])\n",
    "        Y_predicted_job.append(r[-1])\n",
    "        averagefrac.append(r[3])\n",
    "    else:\n",
    "        nodecision.append(r)\n",
    "\n",
    "# [jobID, totaljobduration, predictionduration, localsamplefrac, len(df), decision_threshold, truelabel, predictedlabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of Y_true :  155797\n",
      "Len of Y_pred :  155797\n",
      "Overall accuracy on test set:  0.8603952579317958\n",
      "Calculating Score: \n",
      "precision    : [0.86177494 0.85747706]\n",
      "recall       : [0.92747991 0.7457353 ]\n",
      "fscore       : [0.89342101 0.79771205]\n",
      "support      : [98290 57507]\n",
      "Confusion matrix:\n",
      "Predicted       0      1     All\n",
      "True                            \n",
      "0           91162   7128   98290\n",
      "1           14622  42885   57507\n",
      "All        105784  50013  155797\n",
      "*********Test Results End**************\n"
     ]
    }
   ],
   "source": [
    "print('Len of Y_true : ', len(Y_true_job))\n",
    "print('Len of Y_pred : ', len(Y_predicted_job))\n",
    "\n",
    "print(\"Overall accuracy on test set: \", np.mean(np.equal(Y_true_job, Y_predicted_job)))\n",
    "\n",
    "print(\"Calculating Score: \")\n",
    "precision, recall, fscore, support = score(Y_true_job, Y_predicted_job)\n",
    "print('precision    : {}'.format(precision))\n",
    "print('recall       : {}'.format(recall))\n",
    "print('fscore       : {}'.format(fscore))\n",
    "print('support      : {}'.format(support))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(pd.Series(Y_true_job), pd.Series(Y_predicted_job), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print('*********Test Results End**************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4554412016763692"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(averagefrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4568"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40387364, None, None, 0.3333333333333333, 9, 0.95, 1, 0],\n",
       " [40387402, None, None, 0.3, 10, 0.95, 0, 0],\n",
       " [40387420, None, None, 0.75, 4, 0.95, 1, 0],\n",
       " [40387451, None, None, 0.2727272727272727, 11, 0.95, 1, 1],\n",
       " [40387457, None, None, 0.21428571428571427, 14, 0.95, 0, 0],\n",
       " [40387462, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387470, None, None, 1.0625, 16, 0.95, 1, -1],\n",
       " [40387484, None, None, 0.3, 10, 0.95, 1, 1],\n",
       " [40387495, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387497, None, None, 0.3333333333333333, 9, 0.95, 1, 1],\n",
       " [40387498, None, None, 0.3, 10, 0.95, 0, 0],\n",
       " [40387539, None, None, 0.21428571428571427, 14, 0.95, 0, 0],\n",
       " [40387559, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387567, None, None, 1.0, 2, 0.95, 1, 0],\n",
       " [40387590, None, None, 0.2727272727272727, 11, 0.95, 0, 0],\n",
       " [40387591, None, None, 0.25, 12, 0.95, 1, 0],\n",
       " [40387610, None, None, 0.75, 4, 0.95, 1, 0],\n",
       " [40387629, None, None, 1.0909090909090908, 11, 0.95, 1, -1],\n",
       " [40387635, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387646, None, None, 0.2727272727272727, 11, 0.95, 1, 1],\n",
       " [40387669, None, None, 0.2727272727272727, 11, 0.95, 0, 0],\n",
       " [40387685, None, None, 0.10344827586206896, 29, 0.95, 1, 0],\n",
       " [40387705, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387708, None, None, 0.0967741935483871, 31, 0.95, 0, 0],\n",
       " [40387711, None, None, 0.15, 20, 0.95, 1, 0],\n",
       " [40387724, None, None, 0.2727272727272727, 11, 0.95, 0, 0],\n",
       " [40387730, None, None, 0.2727272727272727, 11, 0.95, 1, 1],\n",
       " [40387748, None, None, 0.1111111111111111, 27, 0.95, 1, 0],\n",
       " [40387752, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387761, None, None, 0.14285714285714285, 21, 0.95, 1, 0],\n",
       " [40387816, None, None, 0.21428571428571427, 14, 0.95, 0, 0],\n",
       " [40387826, None, None, 0.09090909090909091, 33, 0.95, 0, 0],\n",
       " [40387831, None, None, 0.3333333333333333, 9, 0.95, 1, 0],\n",
       " [40387857, None, None, 0.12, 25, 0.95, 1, 0],\n",
       " [40387863, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387867, None, None, 0.12, 25, 0.95, 1, 0],\n",
       " [40387869, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387887, None, None, 0.09375, 32, 0.95, 0, 0],\n",
       " [40387934, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387945, None, None, 0.25, 12, 0.95, 1, 1],\n",
       " [40387946, None, None, 0.09375, 32, 0.95, 0, 0],\n",
       " [40387949, None, None, 0.2727272727272727, 11, 0.95, 1, 1],\n",
       " [40387955, None, None, 0.42857142857142855, 7, 0.95, 1, 0],\n",
       " [40387972, None, None, 0.3333333333333333, 9, 0.95, 0, 0],\n",
       " [40387987, None, None, 0.21428571428571427, 14, 0.95, 1, 1],\n",
       " [40388074, None, None, 0.0967741935483871, 31, 0.95, 0, 0],\n",
       " [40388116, None, None, 0.21428571428571427, 14, 0.95, 1, 1],\n",
       " [40388137, None, None, 0.0967741935483871, 31, 0.95, 0, 0],\n",
       " [40388153, None, None, 0.1875, 16, 0.95, 0, 1],\n",
       " [40388158, None, None, 0.21428571428571427, 14, 0.95, 1, 1]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_results[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
